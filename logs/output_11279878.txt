no change     /scratch/project_465001389/chandler_scratch/miniconda3/condabin/conda
no change     /scratch/project_465001389/chandler_scratch/miniconda3/bin/conda
no change     /scratch/project_465001389/chandler_scratch/miniconda3/bin/conda-env
no change     /scratch/project_465001389/chandler_scratch/miniconda3/bin/activate
no change     /scratch/project_465001389/chandler_scratch/miniconda3/bin/deactivate
no change     /scratch/project_465001389/chandler_scratch/miniconda3/etc/profile.d/conda.sh
no change     /scratch/project_465001389/chandler_scratch/miniconda3/etc/fish/conf.d/conda.fish
no change     /scratch/project_465001389/chandler_scratch/miniconda3/shell/condabin/Conda.psm1
no change     /scratch/project_465001389/chandler_scratch/miniconda3/shell/condabin/conda-hook.ps1
no change     /scratch/project_465001389/chandler_scratch/miniconda3/lib/python3.12/site-packages/xontrib/conda.xsh
no change     /scratch/project_465001389/chandler_scratch/miniconda3/etc/profile.d/conda.csh
no change     /users/doloriel/.bashrc
No action taken.

CondaError: Run 'conda init' before 'conda activate'

2025-05-27 20:44:21,442 - 10 - main_eval.py - eval - arch tanet
2025-05-27 20:44:21,444 - 10 - main_eval.py - eval - baseline source
2025-05-27 20:44:21,444 - 10 - main_eval.py - eval - batch_size 8
2025-05-27 20:44:21,444 - 10 - main_eval.py - eval - before_norm False
2025-05-27 20:44:21,444 - 10 - main_eval.py - eval - chosen_blocks ['layer3', 'layer4']
2025-05-27 20:44:21,444 - 10 - main_eval.py - eval - clip_length 16
2025-05-27 20:44:21,444 - 10 - main_eval.py - eval - compute_stat False
2025-05-27 20:44:21,444 - 10 - main_eval.py - eval - corruptions gauss_shuffled
2025-05-27 20:44:21,444 - 10 - main_eval.py - eval - dataset ucf101
2025-05-27 20:44:21,444 - 10 - main_eval.py - eval - datatype vid
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - debug False
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - drop_path_rate 0.2
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - evaluate_baselines False
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - fix_BNS True
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - flip_ratio 0
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - frame_interval 2
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - frame_uniform True
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - full_res False
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - gpus [0]
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - if_pred_consistency True
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - if_sample_tta_aug_views True
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - if_spatial_rand_cropping True
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - if_tta_standard tta_online
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - img_feature_dim 256
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - img_norm_cfg {'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_bgr': False}
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - input_mean [0.485, 0.456, 0.406]
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - input_size 224
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - input_std [0.229, 0.224, 0.225]
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - lambda_feature_reg 1
2025-05-27 20:44:21,445 - 10 - main_eval.py - eval - lambda_pred_consis 0.1
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - loss_type nll
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - lr 5e-05
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - modality RGB
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - model_path /scratch/project_465001897/datasets/ucf/model_tanet_ucf/tanet_ucf.pth.tar
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - momentum 0.9
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - momentum_bns 0.1
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - momentum_mvg 0.1
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - moving_avg True
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - n_augmented_views 2
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - n_epoch_adapat 1
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - n_gradient_steps 1
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - norm False
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - num_clips 1
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - partial_bn False
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - patch_size (2, 4, 4)
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - print_freq 20
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - reduce_dim True
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - reg_type l1_loss
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - result_dir /scratch/project_465001897/datasets/ucf/results/tanet_ucf101/tta_gauss_shuffled
2025-05-27 20:44:21,446 - 10 - main_eval.py - eval - root_path None
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - running_manner True
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - sample_style uniform-1
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - scale_size 256
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - spatiotemp_mean_clean_file /scratch/project_465001897/datasets/ucf/source_statistics_tanet_ucf/list_spatiotemp_mean_20220908_235138.npy
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - spatiotemp_var_clean_file /scratch/project_465001897/datasets/ucf/source_statistics_tanet_ucf/list_spatiotemp_var_20220908_235138.npy
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - stat_reg mean_var
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - stat_type ['spatiotemp']
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - test_crops 1
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - tta True
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - tta_view_sample_style_list ['uniform_equidist']
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - update_only_bn_affine False
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - use_pretrained False
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - use_src_stat_in_reg True
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - val_vid_list /scratch/project_465001897/datasets/ucf/list_video_perturbations_ucf/gauss_shuffled.txt
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - verbose True
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - vid_format 
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - video_data_dir /scratch/project_465001897/datasets/ucf/val_corruptions
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - weight_decay 0.0005
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - window_size (8, 7, 7)
2025-05-27 20:44:21,447 - 10 - main_eval.py - eval - workers 4
/scratch/project_465001389/chandler_scratch/miniconda3/envs/videotta/lib/python3.8/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.
  warnings.warn(
/scratch/project_465001389/chandler_scratch/miniconda3/envs/videotta/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
2025-05-27 20:44:29,618 - 10 - main_eval.py - eval - Loading /scratch/project_465001897/datasets/ucf/model_tanet_ucf/tanet_ucf.pth.tar
2025-05-27 20:44:29,739 - 10 - utils_.py - model_analysis - #################################################
2025-05-27 20:44:29,739 - 10 - utils_.py - model_analysis - Number of trainable parameters: 24985093
2025-05-27 20:44:29,739 - 10 - utils_.py - model_analysis - #################################################
apex is not installed
####Starting Evaluation for ::: gauss_shuffled corruption####

                   Initializing TSN with base model: resnet50.
                   TSN Configurations:
                   input_modality:     RGB
                   num_segments:       16
                   new_length:         1
                   consensus_module:   avg
                   dropout_ratio:      0.8
                   img_feature_dim:    256
                   
=> base model: resnet50
Adding temporal adaptive moduel...
=> Processing this stage with 3 blocks residual
TAM with kernel_size 3.
TAM with kernel_size 3.
TAM with kernel_size 3.
=> Processing this stage with 4 blocks residual
TAM with kernel_size 3.
TAM with kernel_size 3.
TAM with kernel_size 3.
TAM with kernel_size 3.
=> Processing this stage with 6 blocks residual
TAM with kernel_size 3.
TAM with kernel_size 3.
TAM with kernel_size 3.
TAM with kernel_size 3.
TAM with kernel_size 3.
TAM with kernel_size 3.
=> Processing this stage with 3 blocks residual
TAM with kernel_size 3.
TAM with kernel_size 3.
TAM with kernel_size 3.
model epoch 50 best prec@1: 96.80147933657447
Model Structure
DataParallel(
  (module): TSN(
    (base_model): ResNet(
      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
      (layer1): Sequential(
        (0): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(64, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(16, 64, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (1): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(64, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(16, 64, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (2): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(64, 16, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(16, 64, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
      )
      (layer2): Sequential(
        (0): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (1): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (2): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (3): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(128, 32, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(32, 128, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
      )
      (layer3): Sequential(
        (0): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (1): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (2): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (3): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (4): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (5): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(256, 64, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(64, 256, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
      )
      (layer4): Sequential(
        (0): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
            (downsample): Sequential(
              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            )
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (1): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
        (2): TemporalBottleneck(
          (net): Bottleneck(
            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (relu): ReLU(inplace=True)
          )
          (tam): TAM(
            (G): Sequential(
              (0): Linear(in_features=16, out_features=32, bias=False)
              (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Linear(in_features=32, out_features=3, bias=False)
              (4): Softmax(dim=-1)
            )
            (L): Sequential(
              (0): Conv1d(512, 128, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)
              (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (2): ReLU(inplace=True)
              (3): Conv1d(128, 512, kernel_size=(1,), stride=(1,), bias=False)
              (4): Sigmoid()
            )
          )
        )
      )
      (avgpool): AdaptiveAvgPool2d(output_size=1)
      (fc): Dropout(p=0.8, inplace=False)
    )
    (new_fc): Linear(in_features=2048, out_features=101, bias=True)
    (consensus): ConsensusModule()
  )
)
2025-05-27 20:44:41,596 - 10 - basics.py - tta_standard - TTA Epoch1: [0/473]	Time 11.784 (11.784)	Loss reg 13.2129 (13.2129)	Loss consis 3.8474 (3.8474)	Prec@1 37.500 (37.500)	Prec@5 50.000 (50.000)
2025-05-27 20:44:43,480 - 10 - basics.py - tta_standard - TTA Epoch1: [1/473]	Time 1.884 (6.834)	Loss reg 12.1681 (12.6905)	Loss consis 3.9317 (3.8895)	Prec@1 37.500 (37.500)	Prec@5 50.000 (50.000)
2025-05-27 20:44:45,318 - 10 - basics.py - tta_standard - TTA Epoch1: [2/473]	Time 1.837 (5.169)	Loss reg 11.2968 (12.2259)	Loss consis 4.5444 (4.1078)	Prec@1 12.500 (29.167)	Prec@5 25.000 (41.667)
2025-05-27 20:44:47,155 - 10 - basics.py - tta_standard - TTA Epoch1: [3/473]	Time 1.838 (4.336)	Loss reg 10.5134 (11.7978)	Loss consis 2.4890 (3.7031)	Prec@1 12.500 (25.000)	Prec@5 62.500 (46.875)
2025-05-27 20:44:48,992 - 10 - basics.py - tta_standard - TTA Epoch1: [4/473]	Time 1.837 (3.836)	Loss reg 9.8123 (11.4007)	Loss consis 3.6186 (3.6862)	Prec@1 0.000 (20.000)	Prec@5 25.000 (42.500)
2025-05-27 20:44:50,828 - 10 - basics.py - tta_standard - TTA Epoch1: [5/473]	Time 1.835 (3.503)	Loss reg 9.2227 (11.0377)	Loss consis 4.8006 (3.8720)	Prec@1 0.000 (16.667)	Prec@5 25.000 (39.583)
2025-05-27 20:44:52,663 - 10 - basics.py - tta_standard - TTA Epoch1: [6/473]	Time 1.835 (3.264)	Loss reg 8.7096 (10.7051)	Loss consis 4.5627 (3.9706)	Prec@1 12.500 (16.071)	Prec@5 50.000 (41.071)
2025-05-27 20:44:54,500 - 10 - basics.py - tta_standard - TTA Epoch1: [7/473]	Time 1.837 (3.086)	Loss reg 8.2928 (10.4036)	Loss consis 3.1111 (3.8632)	Prec@1 25.000 (17.188)	Prec@5 37.500 (40.625)
2025-05-27 20:44:56,341 - 10 - basics.py - tta_standard - TTA Epoch1: [8/473]	Time 1.841 (2.948)	Loss reg 7.9543 (10.1314)	Loss consis 3.2638 (3.7966)	Prec@1 12.500 (16.667)	Prec@5 50.000 (41.667)
2025-05-27 20:44:58,180 - 10 - basics.py - tta_standard - TTA Epoch1: [9/473]	Time 1.839 (2.837)	Loss reg 7.7122 (9.8895)	Loss consis 4.0349 (3.8204)	Prec@1 0.000 (15.000)	Prec@5 37.500 (41.250)
2025-05-27 20:45:00,014 - 10 - basics.py - tta_standard - TTA Epoch1: [10/473]	Time 1.834 (2.746)	Loss reg 7.4705 (9.6696)	Loss consis 3.5680 (3.7975)	Prec@1 25.000 (15.909)	Prec@5 50.000 (42.045)
2025-05-27 20:45:01,852 - 10 - basics.py - tta_standard - TTA Epoch1: [11/473]	Time 1.838 (2.670)	Loss reg 7.2996 (9.4721)	Loss consis 3.0142 (3.7322)	Prec@1 0.000 (14.583)	Prec@5 37.500 (41.667)
2025-05-27 20:45:03,694 - 10 - basics.py - tta_standard - TTA Epoch1: [12/473]	Time 1.842 (2.606)	Loss reg 7.1300 (9.2919)	Loss consis 1.5650 (3.5655)	Prec@1 12.500 (14.423)	Prec@5 37.500 (41.346)
2025-05-27 20:45:05,535 - 10 - basics.py - tta_standard - TTA Epoch1: [13/473]	Time 1.841 (2.552)	Loss reg 6.9306 (9.1233)	Loss consis 3.6708 (3.5730)	Prec@1 25.000 (15.179)	Prec@5 37.500 (41.071)
2025-05-27 20:45:07,371 - 10 - basics.py - tta_standard - TTA Epoch1: [14/473]	Time 1.836 (2.504)	Loss reg 6.8408 (8.9711)	Loss consis 1.9187 (3.4627)	Prec@1 0.000 (14.167)	Prec@5 25.000 (40.000)
2025-05-27 20:45:09,209 - 10 - basics.py - tta_standard - TTA Epoch1: [15/473]	Time 1.838 (2.462)	Loss reg 6.7659 (8.8333)	Loss consis 0.9762 (3.3073)	Prec@1 0.000 (13.281)	Prec@5 12.500 (38.281)
2025-05-27 20:45:11,044 - 10 - basics.py - tta_standard - TTA Epoch1: [16/473]	Time 1.834 (2.425)	Loss reg 6.7069 (8.7082)	Loss consis 1.2903 (3.1887)	Prec@1 12.500 (13.235)	Prec@5 37.500 (38.235)
2025-05-27 20:45:12,878 - 10 - basics.py - tta_standard - TTA Epoch1: [17/473]	Time 1.835 (2.393)	Loss reg 6.6843 (8.5958)	Loss consis 1.0867 (3.0719)	Prec@1 12.500 (13.194)	Prec@5 50.000 (38.889)
2025-05-27 20:45:14,712 - 10 - basics.py - tta_standard - TTA Epoch1: [18/473]	Time 1.834 (2.363)	Loss reg 6.6729 (8.4945)	Loss consis 1.0949 (2.9678)	Prec@1 12.500 (13.158)	Prec@5 37.500 (38.816)
2025-05-27 20:45:16,547 - 10 - basics.py - tta_standard - TTA Epoch1: [19/473]	Time 1.834 (2.337)	Loss reg 6.6753 (8.4036)	Loss consis 0.6230 (2.8506)	Prec@1 0.000 (12.500)	Prec@5 0.000 (36.875)
2025-05-27 20:45:18,383 - 10 - basics.py - tta_standard - TTA Epoch1: [20/473]	Time 1.836 (2.313)	Loss reg 6.6440 (8.3198)	Loss consis 0.5906 (2.7430)	Prec@1 12.500 (12.500)	Prec@5 50.000 (37.500)
2025-05-27 20:45:20,219 - 10 - basics.py - tta_standard - TTA Epoch1: [21/473]	Time 1.836 (2.291)	Loss reg 6.6792 (8.2452)	Loss consis 0.1502 (2.6251)	Prec@1 0.000 (11.932)	Prec@5 0.000 (35.795)
2025-05-27 20:45:22,056 - 10 - basics.py - tta_standard - TTA Epoch1: [22/473]	Time 1.837 (2.271)	Loss reg 6.7514 (8.1803)	Loss consis 0.1143 (2.5160)	Prec@1 0.000 (11.413)	Prec@5 12.500 (34.783)
2025-05-27 20:45:23,893 - 10 - basics.py - tta_standard - TTA Epoch1: [23/473]	Time 1.837 (2.253)	Loss reg 6.8523 (8.1249)	Loss consis 0.2656 (2.4222)	Prec@1 0.000 (10.938)	Prec@5 12.500 (33.854)
2025-05-27 20:45:25,734 - 10 - basics.py - tta_standard - TTA Epoch1: [24/473]	Time 1.841 (2.237)	Loss reg 6.8296 (8.0731)	Loss consis 0.5201 (2.3461)	Prec@1 0.000 (10.500)	Prec@5 0.000 (32.500)
2025-05-27 20:45:27,574 - 10 - basics.py - tta_standard - TTA Epoch1: [25/473]	Time 1.839 (2.222)	Loss reg 6.8649 (8.0267)	Loss consis 1.0624 (2.2967)	Prec@1 0.000 (10.096)	Prec@5 0.000 (31.250)
2025-05-27 20:45:29,412 - 10 - basics.py - tta_standard - TTA Epoch1: [26/473]	Time 1.838 (2.207)	Loss reg 6.8860 (7.9844)	Loss consis 0.5276 (2.2312)	Prec@1 0.000 (9.722)	Prec@5 25.000 (31.019)
2025-05-27 20:45:31,246 - 10 - basics.py - tta_standard - TTA Epoch1: [27/473]	Time 1.834 (2.194)	Loss reg 6.8611 (7.9443)	Loss consis 0.4116 (2.1662)	Prec@1 0.000 (9.375)	Prec@5 25.000 (30.804)
2025-05-27 20:45:33,084 - 10 - basics.py - tta_standard - TTA Epoch1: [28/473]	Time 1.839 (2.182)	Loss reg 6.9249 (7.9091)	Loss consis 0.4309 (2.1064)	Prec@1 0.000 (9.052)	Prec@5 0.000 (29.741)
2025-05-27 20:45:34,921 - 10 - basics.py - tta_standard - TTA Epoch1: [29/473]	Time 1.837 (2.170)	Loss reg 6.9544 (7.8773)	Loss consis 0.1348 (2.0407)	Prec@1 0.000 (8.750)	Prec@5 0.000 (28.750)
2025-05-27 20:45:36,755 - 10 - basics.py - tta_standard - TTA Epoch1: [30/473]	Time 1.835 (2.159)	Loss reg 6.9558 (7.8476)	Loss consis 0.2131 (1.9817)	Prec@1 0.000 (8.468)	Prec@5 0.000 (27.823)
2025-05-27 20:45:38,591 - 10 - basics.py - tta_standard - TTA Epoch1: [31/473]	Time 1.836 (2.149)	Loss reg 7.0170 (7.8216)	Loss consis 0.0780 (1.9222)	Prec@1 12.500 (8.594)	Prec@5 12.500 (27.344)
2025-05-27 20:45:40,428 - 10 - basics.py - tta_standard - TTA Epoch1: [32/473]	Time 1.837 (2.140)	Loss reg 7.0495 (7.7982)	Loss consis 0.1131 (1.8674)	Prec@1 0.000 (8.333)	Prec@5 25.000 (27.273)
2025-05-27 20:45:42,261 - 10 - basics.py - tta_standard - TTA Epoch1: [33/473]	Time 1.833 (2.131)	Loss reg 7.0408 (7.7760)	Loss consis 0.0306 (1.8134)	Prec@1 12.500 (8.456)	Prec@5 12.500 (26.838)
2025-05-27 20:45:44,095 - 10 - basics.py - tta_standard - TTA Epoch1: [34/473]	Time 1.834 (2.122)	Loss reg 7.0391 (7.7549)	Loss consis 0.0226 (1.7622)	Prec@1 0.000 (8.214)	Prec@5 25.000 (26.786)
2025-05-27 20:45:45,935 - 10 - basics.py - tta_standard - TTA Epoch1: [35/473]	Time 1.840 (2.115)	Loss reg 7.0346 (7.7349)	Loss consis 0.0194 (1.7138)	Prec@1 0.000 (7.986)	Prec@5 37.500 (27.083)
2025-05-27 20:45:47,778 - 10 - basics.py - tta_standard - TTA Epoch1: [36/473]	Time 1.844 (2.107)	Loss reg 7.0488 (7.7164)	Loss consis 0.0624 (1.6692)	Prec@1 0.000 (7.770)	Prec@5 12.500 (26.689)
2025-05-27 20:45:49,616 - 10 - basics.py - tta_standard - TTA Epoch1: [37/473]	Time 1.837 (2.100)	Loss reg 7.0889 (7.6998)	Loss consis 0.0134 (1.6256)	Prec@1 0.000 (7.566)	Prec@5 12.500 (26.316)
2025-05-27 20:45:51,452 - 10 - basics.py - tta_standard - TTA Epoch1: [38/473]	Time 1.836 (2.093)	Loss reg 7.0648 (7.6836)	Loss consis 0.0083 (1.5841)	Prec@1 0.000 (7.372)	Prec@5 25.000 (26.282)
2025-05-27 20:45:53,286 - 10 - basics.py - tta_standard - TTA Epoch1: [39/473]	Time 1.834 (2.087)	Loss reg 6.9874 (7.6662)	Loss consis 0.4002 (1.5545)	Prec@1 0.000 (7.188)	Prec@5 25.000 (26.250)
2025-05-27 20:45:55,121 - 10 - basics.py - tta_standard - TTA Epoch1: [40/473]	Time 1.834 (2.081)	Loss reg 6.9895 (7.6497)	Loss consis 0.0041 (1.5167)	Prec@1 0.000 (7.012)	Prec@5 12.500 (25.915)
2025-05-27 20:45:56,955 - 10 - basics.py - tta_standard - TTA Epoch1: [41/473]	Time 1.835 (2.075)	Loss reg 6.9312 (7.6325)	Loss consis 0.0592 (1.4820)	Prec@1 0.000 (6.845)	Prec@5 37.500 (26.190)
2025-05-27 20:45:58,795 - 10 - basics.py - tta_standard - TTA Epoch1: [42/473]	Time 1.839 (2.069)	Loss reg 6.8698 (7.6148)	Loss consis 0.0424 (1.4485)	Prec@1 0.000 (6.686)	Prec@5 12.500 (25.872)
2025-05-27 20:46:00,636 - 10 - basics.py - tta_standard - TTA Epoch1: [43/473]	Time 1.841 (2.064)	Loss reg 6.8170 (7.5967)	Loss consis 0.9143 (1.4364)	Prec@1 0.000 (6.534)	Prec@5 12.500 (25.568)
2025-05-27 20:46:02,473 - 10 - basics.py - tta_standard - TTA Epoch1: [44/473]	Time 1.837 (2.059)	Loss reg 6.7326 (7.5775)	Loss consis 0.2960 (1.4111)	Prec@1 12.500 (6.667)	Prec@5 37.500 (25.833)
2025-05-27 20:46:04,309 - 10 - basics.py - tta_standard - TTA Epoch1: [45/473]	Time 1.836 (2.054)	Loss reg 6.6748 (7.5578)	Loss consis 0.3815 (1.3887)	Prec@1 0.000 (6.522)	Prec@5 37.500 (26.087)
2025-05-27 20:46:06,147 - 10 - basics.py - tta_standard - TTA Epoch1: [46/473]	Time 1.838 (2.050)	Loss reg 6.6036 (7.5375)	Loss consis 0.1531 (1.3624)	Prec@1 0.000 (6.383)	Prec@5 12.500 (25.798)
2025-05-27 20:46:08,098 - 10 - basics.py - tta_standard - TTA Epoch1: [47/473]	Time 1.952 (2.048)	Loss reg 6.5220 (7.5164)	Loss consis 0.1543 (1.3372)	Prec@1 12.500 (6.510)	Prec@5 25.000 (25.781)
2025-05-27 20:46:09,936 - 10 - basics.py - tta_standard - TTA Epoch1: [48/473]	Time 1.838 (2.043)	Loss reg 6.4706 (7.4950)	Loss consis 0.2092 (1.3142)	Prec@1 12.500 (6.633)	Prec@5 37.500 (26.020)
2025-05-27 20:46:11,770 - 10 - basics.py - tta_standard - TTA Epoch1: [49/473]	Time 1.833 (2.039)	Loss reg 6.4132 (7.4734)	Loss consis 0.7524 (1.3030)	Prec@1 12.500 (6.750)	Prec@5 12.500 (25.750)
2025-05-27 20:46:13,608 - 10 - basics.py - tta_standard - TTA Epoch1: [50/473]	Time 1.838 (2.035)	Loss reg 6.3422 (7.4512)	Loss consis 0.5493 (1.2882)	Prec@1 0.000 (6.618)	Prec@5 50.000 (26.225)
2025-05-27 20:46:15,444 - 10 - basics.py - tta_standard - TTA Epoch1: [51/473]	Time 1.835 (2.031)	Loss reg 6.2742 (7.4286)	Loss consis 0.7113 (1.2771)	Prec@1 0.000 (6.490)	Prec@5 50.000 (26.683)
2025-05-27 20:46:17,280 - 10 - basics.py - tta_standard - TTA Epoch1: [52/473]	Time 1.837 (2.028)	Loss reg 6.2463 (7.4063)	Loss consis 0.4657 (1.2618)	Prec@1 12.500 (6.604)	Prec@5 12.500 (26.415)
2025-05-27 20:46:19,117 - 10 - basics.py - tta_standard - TTA Epoch1: [53/473]	Time 1.837 (2.024)	Loss reg 6.2120 (7.3842)	Loss consis 0.6848 (1.2511)	Prec@1 12.500 (6.713)	Prec@5 50.000 (26.852)
2025-05-27 20:46:20,954 - 10 - basics.py - tta_standard - TTA Epoch1: [54/473]	Time 1.838 (2.021)	Loss reg 6.2020 (7.3627)	Loss consis 0.8292 (1.2434)	Prec@1 0.000 (6.591)	Prec@5 0.000 (26.364)
2025-05-27 20:46:22,788 - 10 - basics.py - tta_standard - TTA Epoch1: [55/473]	Time 1.834 (2.017)	Loss reg 6.1630 (7.3412)	Loss consis 0.9532 (1.2382)	Prec@1 25.000 (6.920)	Prec@5 37.500 (26.562)
2025-05-27 20:46:24,623 - 10 - basics.py - tta_standard - TTA Epoch1: [56/473]	Time 1.835 (2.014)	Loss reg 6.1062 (7.3196)	Loss consis 1.4131 (1.2413)	Prec@1 0.000 (6.798)	Prec@5 50.000 (26.974)
2025-05-27 20:46:26,458 - 10 - basics.py - tta_standard - TTA Epoch1: [57/473]	Time 1.835 (2.011)	Loss reg 6.0921 (7.2984)	Loss consis 0.0815 (1.2213)	Prec@1 0.000 (6.681)	Prec@5 25.000 (26.940)
2025-05-27 20:46:28,295 - 10 - basics.py - tta_standard - TTA Epoch1: [58/473]	Time 1.837 (2.008)	Loss reg 6.0474 (7.2772)	Loss consis 0.7723 (1.2137)	Prec@1 0.000 (6.568)	Prec@5 25.000 (26.907)
2025-05-27 20:46:30,132 - 10 - basics.py - tta_standard - TTA Epoch1: [59/473]	Time 1.838 (2.005)	Loss reg 6.0195 (7.2563)	Loss consis 0.6112 (1.2037)	Prec@1 12.500 (6.667)	Prec@5 25.000 (26.875)
2025-05-27 20:46:31,975 - 10 - basics.py - tta_standard - TTA Epoch1: [60/473]	Time 1.843 (2.003)	Loss reg 5.9873 (7.2354)	Loss consis 0.4841 (1.1919)	Prec@1 12.500 (6.762)	Prec@5 37.500 (27.049)
2025-05-27 20:46:33,812 - 10 - basics.py - tta_standard - TTA Epoch1: [61/473]	Time 1.837 (2.000)	Loss reg 5.8925 (7.2138)	Loss consis 1.8701 (1.2028)	Prec@1 0.000 (6.653)	Prec@5 50.000 (27.419)
2025-05-27 20:46:35,652 - 10 - basics.py - tta_standard - TTA Epoch1: [62/473]	Time 1.840 (1.997)	Loss reg 5.8778 (7.1926)	Loss consis 0.5134 (1.1919)	Prec@1 0.000 (6.548)	Prec@5 25.000 (27.381)
2025-05-27 20:46:37,490 - 10 - basics.py - tta_standard - TTA Epoch1: [63/473]	Time 1.838 (1.995)	Loss reg 5.8794 (7.1721)	Loss consis 0.1648 (1.1758)	Prec@1 0.000 (6.445)	Prec@5 50.000 (27.734)
2025-05-27 20:46:39,331 - 10 - basics.py - tta_standard - TTA Epoch1: [64/473]	Time 1.841 (1.993)	Loss reg 5.8606 (7.1519)	Loss consis 0.3954 (1.1638)	Prec@1 12.500 (6.538)	Prec@5 50.000 (28.077)
2025-05-27 20:46:41,169 - 10 - basics.py - tta_standard - TTA Epoch1: [65/473]	Time 1.838 (1.990)	Loss reg 5.8128 (7.1316)	Loss consis 0.5037 (1.1538)	Prec@1 12.500 (6.629)	Prec@5 50.000 (28.409)
2025-05-27 20:46:43,006 - 10 - basics.py - tta_standard - TTA Epoch1: [66/473]	Time 1.836 (1.988)	Loss reg 5.8305 (7.1122)	Loss consis 0.3434 (1.1417)	Prec@1 0.000 (6.530)	Prec@5 62.500 (28.918)
2025-05-27 20:46:44,847 - 10 - basics.py - tta_standard - TTA Epoch1: [67/473]	Time 1.842 (1.986)	Loss reg 5.8182 (7.0931)	Loss consis 0.3587 (1.1302)	Prec@1 0.000 (6.434)	Prec@5 50.000 (29.228)
2025-05-27 20:46:46,685 - 10 - basics.py - tta_standard - TTA Epoch1: [68/473]	Time 1.838 (1.984)	Loss reg 5.7726 (7.0740)	Loss consis 0.7779 (1.1251)	Prec@1 0.000 (6.341)	Prec@5 50.000 (29.529)
2025-05-27 20:46:48,522 - 10 - basics.py - tta_standard - TTA Epoch1: [69/473]	Time 1.836 (1.982)	Loss reg 5.7506 (7.0551)	Loss consis 0.3452 (1.1139)	Prec@1 0.000 (6.250)	Prec@5 37.500 (29.643)
2025-05-27 20:46:50,360 - 10 - basics.py - tta_standard - TTA Epoch1: [70/473]	Time 1.838 (1.980)	Loss reg 5.7302 (7.0364)	Loss consis 0.1030 (1.0997)	Prec@1 0.000 (6.162)	Prec@5 12.500 (29.401)
2025-05-27 20:46:52,196 - 10 - basics.py - tta_standard - TTA Epoch1: [71/473]	Time 1.836 (1.978)	Loss reg 5.7228 (7.0182)	Loss consis 0.1847 (1.0870)	Prec@1 12.500 (6.250)	Prec@5 37.500 (29.514)
2025-05-27 20:46:54,038 - 10 - basics.py - tta_standard - TTA Epoch1: [72/473]	Time 1.842 (1.976)	Loss reg 5.7097 (7.0003)	Loss consis 0.0754 (1.0731)	Prec@1 12.500 (6.336)	Prec@5 62.500 (29.966)
2025-05-27 20:46:55,878 - 10 - basics.py - tta_standard - TTA Epoch1: [73/473]	Time 1.840 (1.974)	Loss reg 5.7146 (6.9829)	Loss consis 0.1241 (1.0603)	Prec@1 0.000 (6.250)	Prec@5 25.000 (29.899)
2025-05-27 20:46:57,714 - 10 - basics.py - tta_standard - TTA Epoch1: [74/473]	Time 1.837 (1.972)	Loss reg 5.6958 (6.9657)	Loss consis 0.8233 (1.0572)	Prec@1 12.500 (6.333)	Prec@5 50.000 (30.167)
2025-05-27 20:46:59,549 - 10 - basics.py - tta_standard - TTA Epoch1: [75/473]	Time 1.834 (1.970)	Loss reg 5.6833 (6.9489)	Loss consis 0.0639 (1.0441)	Prec@1 0.000 (6.250)	Prec@5 12.500 (29.934)
2025-05-27 20:47:01,385 - 10 - basics.py - tta_standard - TTA Epoch1: [76/473]	Time 1.837 (1.968)	Loss reg 5.6424 (6.9319)	Loss consis 0.1012 (1.0318)	Prec@1 25.000 (6.494)	Prec@5 50.000 (30.195)
2025-05-27 20:47:03,224 - 10 - basics.py - tta_standard - TTA Epoch1: [77/473]	Time 1.839 (1.967)	Loss reg 5.6691 (6.9157)	Loss consis 0.0183 (1.0188)	Prec@1 0.000 (6.410)	Prec@5 12.500 (29.968)
2025-05-27 20:47:05,059 - 10 - basics.py - tta_standard - TTA Epoch1: [78/473]	Time 1.836 (1.965)	Loss reg 5.6595 (6.8998)	Loss consis 1.0743 (1.0195)	Prec@1 12.500 (6.487)	Prec@5 25.000 (29.905)
2025-05-27 20:47:06,895 - 10 - basics.py - tta_standard - TTA Epoch1: [79/473]	Time 1.836 (1.964)	Loss reg 5.6372 (6.8840)	Loss consis 0.6372 (1.0148)	Prec@1 0.000 (6.406)	Prec@5 12.500 (29.688)
2025-05-27 20:47:08,738 - 10 - basics.py - tta_standard - TTA Epoch1: [80/473]	Time 1.843 (1.962)	Loss reg 5.6097 (6.8683)	Loss consis 0.3012 (1.0060)	Prec@1 0.000 (6.327)	Prec@5 25.000 (29.630)
2025-05-27 20:47:10,574 - 10 - basics.py - tta_standard - TTA Epoch1: [81/473]	Time 1.836 (1.961)	Loss reg 5.6062 (6.8529)	Loss consis 0.0700 (0.9945)	Prec@1 0.000 (6.250)	Prec@5 25.000 (29.573)
2025-05-27 20:47:12,410 - 10 - basics.py - tta_standard - TTA Epoch1: [82/473]	Time 1.837 (1.959)	Loss reg 5.6014 (6.8378)	Loss consis 0.8417 (0.9927)	Prec@1 0.000 (6.175)	Prec@5 37.500 (29.669)
2025-05-27 20:47:14,247 - 10 - basics.py - tta_standard - TTA Epoch1: [83/473]	Time 1.836 (1.958)	Loss reg 5.6159 (6.8233)	Loss consis 0.4043 (0.9857)	Prec@1 0.000 (6.101)	Prec@5 37.500 (29.762)
2025-05-27 20:47:16,080 - 10 - basics.py - tta_standard - TTA Epoch1: [84/473]	Time 1.834 (1.956)	Loss reg 5.6102 (6.8090)	Loss consis 0.7598 (0.9830)	Prec@1 12.500 (6.176)	Prec@5 37.500 (29.853)
2025-05-27 20:47:17,917 - 10 - basics.py - tta_standard - TTA Epoch1: [85/473]	Time 1.837 (1.955)	Loss reg 5.5620 (6.7945)	Loss consis 0.3681 (0.9759)	Prec@1 0.000 (6.105)	Prec@5 50.000 (30.087)
2025-05-27 20:47:19,751 - 10 - basics.py - tta_standard - TTA Epoch1: [86/473]	Time 1.834 (1.953)	Loss reg 5.5821 (6.7806)	Loss consis 0.8008 (0.9739)	Prec@1 0.000 (6.034)	Prec@5 62.500 (30.460)
2025-05-27 20:47:21,588 - 10 - basics.py - tta_standard - TTA Epoch1: [87/473]	Time 1.837 (1.952)	Loss reg 5.5855 (6.7670)	Loss consis 0.0378 (0.9632)	Prec@1 0.000 (5.966)	Prec@5 12.500 (30.256)
2025-05-27 20:47:23,425 - 10 - basics.py - tta_standard - TTA Epoch1: [88/473]	Time 1.837 (1.951)	Loss reg 5.6137 (6.7540)	Loss consis 0.3606 (0.9565)	Prec@1 0.000 (5.899)	Prec@5 37.500 (30.337)
2025-05-27 20:47:25,261 - 10 - basics.py - tta_standard - TTA Epoch1: [89/473]	Time 1.836 (1.949)	Loss reg 5.6038 (6.7412)	Loss consis 0.0408 (0.9463)	Prec@1 0.000 (5.833)	Prec@5 12.500 (30.139)
2025-05-27 20:47:27,099 - 10 - basics.py - tta_standard - TTA Epoch1: [90/473]	Time 1.838 (1.948)	Loss reg 5.5936 (6.7286)	Loss consis 0.0309 (0.9362)	Prec@1 0.000 (5.769)	Prec@5 12.500 (29.945)
2025-05-27 20:47:28,936 - 10 - basics.py - tta_standard - TTA Epoch1: [91/473]	Time 1.836 (1.947)	Loss reg 5.6236 (6.7166)	Loss consis 0.1686 (0.9279)	Prec@1 0.000 (5.707)	Prec@5 12.500 (29.755)
2025-05-27 20:47:30,774 - 10 - basics.py - tta_standard - TTA Epoch1: [92/473]	Time 1.839 (1.946)	Loss reg 5.6068 (6.7047)	Loss consis 1.4526 (0.9335)	Prec@1 12.500 (5.780)	Prec@5 37.500 (29.839)
2025-05-27 20:47:32,610 - 10 - basics.py - tta_standard - TTA Epoch1: [93/473]	Time 1.836 (1.945)	Loss reg 5.5885 (6.6928)	Loss consis 0.3026 (0.9268)	Prec@1 0.000 (5.718)	Prec@5 12.500 (29.654)
2025-05-27 20:47:34,451 - 10 - basics.py - tta_standard - TTA Epoch1: [94/473]	Time 1.840 (1.944)	Loss reg 5.5559 (6.6808)	Loss consis 0.3346 (0.9206)	Prec@1 0.000 (5.658)	Prec@5 25.000 (29.605)
2025-05-27 20:47:36,288 - 10 - basics.py - tta_standard - TTA Epoch1: [95/473]	Time 1.837 (1.942)	Loss reg 5.5410 (6.6690)	Loss consis 0.0173 (0.9112)	Prec@1 0.000 (5.599)	Prec@5 25.000 (29.557)
2025-05-27 20:47:38,124 - 10 - basics.py - tta_standard - TTA Epoch1: [96/473]	Time 1.836 (1.941)	Loss reg 5.5109 (6.6570)	Loss consis 0.6270 (0.9082)	Prec@1 0.000 (5.541)	Prec@5 37.500 (29.639)
2025-05-27 20:47:39,961 - 10 - basics.py - tta_standard - TTA Epoch1: [97/473]	Time 1.836 (1.940)	Loss reg 5.5138 (6.6454)	Loss consis 0.3034 (0.9021)	Prec@1 0.000 (5.485)	Prec@5 25.000 (29.592)
2025-05-27 20:47:41,797 - 10 - basics.py - tta_standard - TTA Epoch1: [98/473]	Time 1.837 (1.939)	Loss reg 5.5056 (6.6339)	Loss consis 0.0575 (0.8935)	Prec@1 0.000 (5.429)	Prec@5 12.500 (29.419)
2025-05-27 20:47:43,634 - 10 - basics.py - tta_standard - TTA Epoch1: [99/473]	Time 1.837 (1.938)	Loss reg 5.5574 (6.6231)	Loss consis 0.0221 (0.8848)	Prec@1 0.000 (5.375)	Prec@5 37.500 (29.500)
2025-05-27 20:47:45,471 - 10 - basics.py - tta_standard - TTA Epoch1: [100/473]	Time 1.837 (1.937)	Loss reg 5.5949 (6.6129)	Loss consis 0.0020 (0.8761)	Prec@1 0.000 (5.322)	Prec@5 25.000 (29.455)
2025-05-27 20:47:47,309 - 10 - basics.py - tta_standard - TTA Epoch1: [101/473]	Time 1.837 (1.936)	Loss reg 5.5893 (6.6029)	Loss consis 0.0154 (0.8677)	Prec@1 0.000 (5.270)	Prec@5 12.500 (29.289)
2025-05-27 20:47:49,146 - 10 - basics.py - tta_standard - TTA Epoch1: [102/473]	Time 1.837 (1.935)	Loss reg 5.6255 (6.5934)	Loss consis 0.1843 (0.8610)	Prec@1 0.000 (5.218)	Prec@5 0.000 (29.005)
2025-05-27 20:47:50,981 - 10 - basics.py - tta_standard - TTA Epoch1: [103/473]	Time 1.836 (1.934)	Loss reg 5.6163 (6.5840)	Loss consis 0.4039 (0.8566)	Prec@1 12.500 (5.288)	Prec@5 37.500 (29.087)
2025-05-27 20:47:52,818 - 10 - basics.py - tta_standard - TTA Epoch1: [104/473]	Time 1.837 (1.933)	Loss reg 5.5832 (6.5745)	Loss consis 0.0209 (0.8487)	Prec@1 12.500 (5.357)	Prec@5 25.000 (29.048)
2025-05-27 20:47:54,655 - 10 - basics.py - tta_standard - TTA Epoch1: [105/473]	Time 1.837 (1.932)	Loss reg 5.5854 (6.5651)	Loss consis 0.0403 (0.8410)	Prec@1 0.000 (5.307)	Prec@5 50.000 (29.245)
2025-05-27 20:47:56,495 - 10 - basics.py - tta_standard - TTA Epoch1: [106/473]	Time 1.840 (1.932)	Loss reg 5.5964 (6.5561)	Loss consis 0.0559 (0.8337)	Prec@1 0.000 (5.257)	Prec@5 50.000 (29.439)
2025-05-27 20:47:58,336 - 10 - basics.py - tta_standard - TTA Epoch1: [107/473]	Time 1.841 (1.931)	Loss reg 5.5765 (6.5470)	Loss consis 0.2810 (0.8286)	Prec@1 0.000 (5.208)	Prec@5 25.000 (29.398)
2025-05-27 20:48:00,175 - 10 - basics.py - tta_standard - TTA Epoch1: [108/473]	Time 1.838 (1.930)	Loss reg 5.5805 (6.5381)	Loss consis 0.1203 (0.8221)	Prec@1 0.000 (5.161)	Prec@5 62.500 (29.702)
2025-05-27 20:48:02,011 - 10 - basics.py - tta_standard - TTA Epoch1: [109/473]	Time 1.837 (1.929)	Loss reg 5.5875 (6.5295)	Loss consis 0.0559 (0.8151)	Prec@1 0.000 (5.114)	Prec@5 12.500 (29.545)
2025-05-27 20:48:03,849 - 10 - basics.py - tta_standard - TTA Epoch1: [110/473]	Time 1.838 (1.928)	Loss reg 5.5573 (6.5207)	Loss consis 0.1292 (0.8089)	Prec@1 0.000 (5.068)	Prec@5 12.500 (29.392)
2025-05-27 20:48:05,684 - 10 - basics.py - tta_standard - TTA Epoch1: [111/473]	Time 1.835 (1.927)	Loss reg 5.5269 (6.5119)	Loss consis 0.1369 (0.8029)	Prec@1 0.000 (5.022)	Prec@5 37.500 (29.464)
2025-05-27 20:48:07,522 - 10 - basics.py - tta_standard - TTA Epoch1: [112/473]	Time 1.837 (1.927)	Loss reg 5.5407 (6.5033)	Loss consis 0.0260 (0.7961)	Prec@1 0.000 (4.978)	Prec@5 25.000 (29.425)
2025-05-27 20:48:09,360 - 10 - basics.py - tta_standard - TTA Epoch1: [113/473]	Time 1.838 (1.926)	Loss reg 5.5204 (6.4946)	Loss consis 0.0080 (0.7891)	Prec@1 0.000 (4.934)	Prec@5 25.000 (29.386)
2025-05-27 20:48:11,197 - 10 - basics.py - tta_standard - TTA Epoch1: [114/473]	Time 1.837 (1.925)	Loss reg 5.5092 (6.4861)	Loss consis 0.6299 (0.7878)	Prec@1 25.000 (5.109)	Prec@5 50.000 (29.565)
2025-05-27 20:48:13,032 - 10 - basics.py - tta_standard - TTA Epoch1: [115/473]	Time 1.836 (1.924)	Loss reg 5.4669 (6.4773)	Loss consis 0.8923 (0.7887)	Prec@1 0.000 (5.065)	Prec@5 37.500 (29.634)
2025-05-27 20:48:14,870 - 10 - basics.py - tta_standard - TTA Epoch1: [116/473]	Time 1.838 (1.924)	Loss reg 5.4405 (6.4684)	Loss consis 0.3550 (0.7850)	Prec@1 25.000 (5.235)	Prec@5 50.000 (29.808)
2025-05-27 20:48:16,706 - 10 - basics.py - tta_standard - TTA Epoch1: [117/473]	Time 1.836 (1.923)	Loss reg 5.4276 (6.4596)	Loss consis 0.0046 (0.7783)	Prec@1 0.000 (5.191)	Prec@5 12.500 (29.661)
2025-05-27 20:48:18,541 - 10 - basics.py - tta_standard - TTA Epoch1: [118/473]	Time 1.835 (1.922)	Loss reg 5.3664 (6.4504)	Loss consis 1.1951 (0.7818)	Prec@1 0.000 (5.147)	Prec@5 37.500 (29.727)
2025-05-27 20:48:20,375 - 10 - basics.py - tta_standard - TTA Epoch1: [119/473]	Time 1.835 (1.921)	Loss reg 5.3315 (6.4411)	Loss consis 0.0799 (0.7760)	Prec@1 0.000 (5.104)	Prec@5 25.000 (29.688)
2025-05-27 20:48:22,214 - 10 - basics.py - tta_standard - TTA Epoch1: [120/473]	Time 1.839 (1.921)	Loss reg 5.2985 (6.4317)	Loss consis 0.9003 (0.7770)	Prec@1 0.000 (5.062)	Prec@5 37.500 (29.752)
2025-05-27 20:48:24,050 - 10 - basics.py - tta_standard - TTA Epoch1: [121/473]	Time 1.837 (1.920)	Loss reg 5.3185 (6.4225)	Loss consis 0.0144 (0.7708)	Prec@1 0.000 (5.020)	Prec@5 25.000 (29.713)
2025-05-27 20:48:25,889 - 10 - basics.py - tta_standard - TTA Epoch1: [122/473]	Time 1.838 (1.919)	Loss reg 5.3191 (6.4136)	Loss consis 0.0599 (0.7650)	Prec@1 0.000 (4.980)	Prec@5 62.500 (29.980)
2025-05-27 20:48:27,726 - 10 - basics.py - tta_standard - TTA Epoch1: [123/473]	Time 1.837 (1.919)	Loss reg 5.2540 (6.4042)	Loss consis 0.6521 (0.7641)	Prec@1 25.000 (5.141)	Prec@5 50.000 (30.141)
2025-05-27 20:48:29,570 - 10 - basics.py - tta_standard - TTA Epoch1: [124/473]	Time 1.844 (1.918)	Loss reg 5.2342 (6.3949)	Loss consis 0.7004 (0.7636)	Prec@1 12.500 (5.200)	Prec@5 37.500 (30.200)
2025-05-27 20:48:31,409 - 10 - basics.py - tta_standard - TTA Epoch1: [125/473]	Time 1.839 (1.917)	Loss reg 5.1721 (6.3851)	Loss consis 1.1078 (0.7663)	Prec@1 12.500 (5.258)	Prec@5 50.000 (30.357)
2025-05-27 20:48:33,245 - 10 - basics.py - tta_standard - TTA Epoch1: [126/473]	Time 1.836 (1.917)	Loss reg 5.1732 (6.3756)	Loss consis 0.0136 (0.7604)	Prec@1 0.000 (5.217)	Prec@5 62.500 (30.610)
2025-05-27 20:48:35,082 - 10 - basics.py - tta_standard - TTA Epoch1: [127/473]	Time 1.836 (1.916)	Loss reg 5.1613 (6.3661)	Loss consis 0.6225 (0.7593)	Prec@1 12.500 (5.273)	Prec@5 25.000 (30.566)
2025-05-27 20:48:36,918 - 10 - basics.py - tta_standard - TTA Epoch1: [128/473]	Time 1.836 (1.916)	Loss reg 5.1360 (6.3566)	Loss consis 1.5724 (0.7656)	Prec@1 25.000 (5.426)	Prec@5 37.500 (30.620)
2025-05-27 20:48:38,755 - 10 - basics.py - tta_standard - TTA Epoch1: [129/473]	Time 1.837 (1.915)	Loss reg 5.1329 (6.3472)	Loss consis 0.5449 (0.7639)	Prec@1 12.500 (5.481)	Prec@5 37.500 (30.673)
2025-05-27 20:48:40,594 - 10 - basics.py - tta_standard - TTA Epoch1: [130/473]	Time 1.838 (1.914)	Loss reg 5.1415 (6.3380)	Loss consis 0.0056 (0.7581)	Prec@1 0.000 (5.439)	Prec@5 37.500 (30.725)
2025-05-27 20:48:42,430 - 10 - basics.py - tta_standard - TTA Epoch1: [131/473]	Time 1.837 (1.914)	Loss reg 5.1436 (6.3289)	Loss consis 0.1578 (0.7536)	Prec@1 0.000 (5.398)	Prec@5 25.000 (30.682)
2025-05-27 20:48:44,267 - 10 - basics.py - tta_standard - TTA Epoch1: [132/473]	Time 1.837 (1.913)	Loss reg 5.0791 (6.3195)	Loss consis 0.6990 (0.7532)	Prec@1 0.000 (5.357)	Prec@5 25.000 (30.639)
2025-05-27 20:48:46,104 - 10 - basics.py - tta_standard - TTA Epoch1: [133/473]	Time 1.837 (1.913)	Loss reg 5.0584 (6.3101)	Loss consis 0.1889 (0.7490)	Prec@1 12.500 (5.410)	Prec@5 37.500 (30.690)
2025-05-27 20:48:47,940 - 10 - basics.py - tta_standard - TTA Epoch1: [134/473]	Time 1.837 (1.912)	Loss reg 5.0243 (6.3006)	Loss consis 1.0346 (0.7511)	Prec@1 0.000 (5.370)	Prec@5 12.500 (30.556)
2025-05-27 20:48:49,780 - 10 - basics.py - tta_standard - TTA Epoch1: [135/473]	Time 1.839 (1.912)	Loss reg 5.0169 (6.2911)	Loss consis 0.0865 (0.7462)	Prec@1 0.000 (5.331)	Prec@5 12.500 (30.423)
2025-05-27 20:48:51,618 - 10 - basics.py - tta_standard - TTA Epoch1: [136/473]	Time 1.838 (1.911)	Loss reg 5.0026 (6.2817)	Loss consis 0.7243 (0.7460)	Prec@1 0.000 (5.292)	Prec@5 75.000 (30.748)
2025-05-27 20:48:53,453 - 10 - basics.py - tta_standard - TTA Epoch1: [137/473]	Time 1.835 (1.910)	Loss reg 4.9897 (6.2724)	Loss consis 0.2888 (0.7427)	Prec@1 0.000 (5.254)	Prec@5 12.500 (30.616)
2025-05-27 20:48:55,295 - 10 - basics.py - tta_standard - TTA Epoch1: [138/473]	Time 1.842 (1.910)	Loss reg 4.9836 (6.2631)	Loss consis 0.1622 (0.7385)	Prec@1 0.000 (5.216)	Prec@5 25.000 (30.576)
2025-05-27 20:48:57,133 - 10 - basics.py - tta_standard - TTA Epoch1: [139/473]	Time 1.838 (1.909)	Loss reg 4.9897 (6.2540)	Loss consis 0.9980 (0.7404)	Prec@1 0.000 (5.179)	Prec@5 12.500 (30.446)
2025-05-27 20:48:58,979 - 10 - basics.py - tta_standard - TTA Epoch1: [140/473]	Time 1.846 (1.909)	Loss reg 5.0256 (6.2453)	Loss consis 0.0673 (0.7356)	Prec@1 0.000 (5.142)	Prec@5 37.500 (30.496)
2025-05-27 20:49:00,816 - 10 - basics.py - tta_standard - TTA Epoch1: [141/473]	Time 1.837 (1.908)	Loss reg 5.0055 (6.2366)	Loss consis 0.0322 (0.7307)	Prec@1 0.000 (5.106)	Prec@5 37.500 (30.546)
2025-05-27 20:49:02,655 - 10 - basics.py - tta_standard - TTA Epoch1: [142/473]	Time 1.839 (1.908)	Loss reg 4.9846 (6.2278)	Loss consis 0.0039 (0.7256)	Prec@1 0.000 (5.070)	Prec@5 37.500 (30.594)
2025-05-27 20:49:04,491 - 10 - basics.py - tta_standard - TTA Epoch1: [143/473]	Time 1.836 (1.907)	Loss reg 4.9922 (6.2192)	Loss consis 0.1161 (0.7213)	Prec@1 12.500 (5.122)	Prec@5 50.000 (30.729)
2025-05-27 20:49:06,330 - 10 - basics.py - tta_standard - TTA Epoch1: [144/473]	Time 1.839 (1.907)	Loss reg 4.9793 (6.2107)	Loss consis 0.0649 (0.7168)	Prec@1 0.000 (5.086)	Prec@5 37.500 (30.776)
2025-05-27 20:49:08,163 - 10 - basics.py - tta_standard - TTA Epoch1: [145/473]	Time 1.833 (1.907)	Loss reg 4.9947 (6.2023)	Loss consis 0.0097 (0.7120)	Prec@1 0.000 (5.051)	Prec@5 37.500 (30.822)
2025-05-27 20:49:10,002 - 10 - basics.py - tta_standard - TTA Epoch1: [146/473]	Time 1.838 (1.906)	Loss reg 4.9809 (6.1940)	Loss consis 0.3971 (0.7098)	Prec@1 25.000 (5.187)	Prec@5 25.000 (30.782)
2025-05-27 20:49:11,836 - 10 - basics.py - tta_standard - TTA Epoch1: [147/473]	Time 1.835 (1.906)	Loss reg 4.9843 (6.1859)	Loss consis 0.4738 (0.7082)	Prec@1 12.500 (5.236)	Prec@5 50.000 (30.912)
2025-05-27 20:49:13,671 - 10 - basics.py - tta_standard - TTA Epoch1: [148/473]	Time 1.835 (1.905)	Loss reg 5.0197 (6.1780)	Loss consis 0.0104 (0.7036)	Prec@1 0.000 (5.201)	Prec@5 12.500 (30.789)
2025-05-27 20:49:15,505 - 10 - basics.py - tta_standard - TTA Epoch1: [149/473]	Time 1.834 (1.905)	Loss reg 5.0145 (6.1703)	Loss consis 0.0247 (0.6990)	Prec@1 0.000 (5.167)	Prec@5 25.000 (30.750)
2025-05-27 20:49:17,343 - 10 - basics.py - tta_standard - TTA Epoch1: [150/473]	Time 1.838 (1.904)	Loss reg 4.9993 (6.1625)	Loss consis 0.1207 (0.6952)	Prec@1 0.000 (5.132)	Prec@5 37.500 (30.795)
2025-05-27 20:49:19,181 - 10 - basics.py - tta_standard - TTA Epoch1: [151/473]	Time 1.838 (1.904)	Loss reg 4.9962 (6.1549)	Loss consis 0.9442 (0.6968)	Prec@1 0.000 (5.099)	Prec@5 62.500 (31.003)
2025-05-27 20:49:21,016 - 10 - basics.py - tta_standard - TTA Epoch1: [152/473]	Time 1.835 (1.903)	Loss reg 4.9864 (6.1472)	Loss consis 0.2829 (0.6941)	Prec@1 0.000 (5.065)	Prec@5 62.500 (31.209)
2025-05-27 20:49:22,856 - 10 - basics.py - tta_standard - TTA Epoch1: [153/473]	Time 1.840 (1.903)	Loss reg 4.9701 (6.1396)	Loss consis 0.0601 (0.6900)	Prec@1 0.000 (5.032)	Prec@5 50.000 (31.331)
2025-05-27 20:49:24,695 - 10 - basics.py - tta_standard - TTA Epoch1: [154/473]	Time 1.839 (1.902)	Loss reg 4.9917 (6.1322)	Loss consis 0.0245 (0.6857)	Prec@1 0.000 (5.000)	Prec@5 25.000 (31.290)
2025-05-27 20:49:26,534 - 10 - basics.py - tta_standard - TTA Epoch1: [155/473]	Time 1.839 (1.902)	Loss reg 4.9805 (6.1248)	Loss consis 0.4836 (0.6844)	Prec@1 0.000 (4.968)	Prec@5 37.500 (31.330)
2025-05-27 20:49:28,370 - 10 - basics.py - tta_standard - TTA Epoch1: [156/473]	Time 1.836 (1.902)	Loss reg 4.9547 (6.1173)	Loss consis 0.3717 (0.6824)	Prec@1 0.000 (4.936)	Prec@5 37.500 (31.369)
2025-05-27 20:49:30,207 - 10 - basics.py - tta_standard - TTA Epoch1: [157/473]	Time 1.837 (1.901)	Loss reg 4.9605 (6.1100)	Loss consis 0.0283 (0.6783)	Prec@1 0.000 (4.905)	Prec@5 12.500 (31.250)
2025-05-27 20:49:32,044 - 10 - basics.py - tta_standard - TTA Epoch1: [158/473]	Time 1.837 (1.901)	Loss reg 4.9606 (6.1028)	Loss consis 0.7558 (0.6788)	Prec@1 0.000 (4.874)	Prec@5 50.000 (31.368)
2025-05-27 20:49:33,883 - 10 - basics.py - tta_standard - TTA Epoch1: [159/473]	Time 1.839 (1.900)	Loss reg 4.9407 (6.0955)	Loss consis 0.6928 (0.6789)	Prec@1 12.500 (4.922)	Prec@5 37.500 (31.406)
2025-05-27 20:49:35,719 - 10 - basics.py - tta_standard - TTA Epoch1: [160/473]	Time 1.836 (1.900)	Loss reg 4.9269 (6.0883)	Loss consis 0.2206 (0.6760)	Prec@1 0.000 (4.891)	Prec@5 50.000 (31.522)
2025-05-27 20:49:37,555 - 10 - basics.py - tta_standard - TTA Epoch1: [161/473]	Time 1.836 (1.900)	Loss reg 4.9207 (6.0811)	Loss consis 0.1902 (0.6730)	Prec@1 0.000 (4.861)	Prec@5 37.500 (31.559)
2025-05-27 20:49:39,393 - 10 - basics.py - tta_standard - TTA Epoch1: [162/473]	Time 1.837 (1.899)	Loss reg 4.8577 (6.0735)	Loss consis 0.2323 (0.6703)	Prec@1 25.000 (4.985)	Prec@5 50.000 (31.672)
2025-05-27 20:49:41,227 - 10 - basics.py - tta_standard - TTA Epoch1: [163/473]	Time 1.835 (1.899)	Loss reg 4.8432 (6.0660)	Loss consis 0.1136 (0.6669)	Prec@1 0.000 (4.954)	Prec@5 37.500 (31.707)
2025-05-27 20:49:43,059 - 10 - basics.py - tta_standard - TTA Epoch1: [164/473]	Time 1.832 (1.898)	Loss reg 4.8313 (6.0586)	Loss consis 0.1164 (0.6636)	Prec@1 0.000 (4.924)	Prec@5 37.500 (31.742)
2025-05-27 20:49:44,892 - 10 - basics.py - tta_standard - TTA Epoch1: [165/473]	Time 1.833 (1.898)	Loss reg 4.8312 (6.0512)	Loss consis 0.0324 (0.6598)	Prec@1 0.000 (4.895)	Prec@5 37.500 (31.777)
2025-05-27 20:49:46,729 - 10 - basics.py - tta_standard - TTA Epoch1: [166/473]	Time 1.837 (1.898)	Loss reg 4.8436 (6.0439)	Loss consis 0.0430 (0.6561)	Prec@1 0.000 (4.865)	Prec@5 12.500 (31.662)
2025-05-27 20:49:48,567 - 10 - basics.py - tta_standard - TTA Epoch1: [167/473]	Time 1.838 (1.897)	Loss reg 4.8209 (6.0367)	Loss consis 1.1897 (0.6593)	Prec@1 25.000 (4.985)	Prec@5 62.500 (31.845)
2025-05-27 20:49:50,413 - 10 - basics.py - tta_standard - TTA Epoch1: [168/473]	Time 1.846 (1.897)	Loss reg 4.7957 (6.0293)	Loss consis 0.3282 (0.6573)	Prec@1 25.000 (5.104)	Prec@5 50.000 (31.953)
2025-05-27 20:49:52,255 - 10 - basics.py - tta_standard - TTA Epoch1: [169/473]	Time 1.843 (1.897)	Loss reg 4.8077 (6.0221)	Loss consis 0.0401 (0.6537)	Prec@1 0.000 (5.074)	Prec@5 62.500 (32.132)
2025-05-27 20:49:54,093 - 10 - basics.py - tta_standard - TTA Epoch1: [170/473]	Time 1.838 (1.896)	Loss reg 4.8221 (6.0151)	Loss consis 0.0047 (0.6499)	Prec@1 0.000 (5.044)	Prec@5 37.500 (32.164)
2025-05-27 20:49:55,929 - 10 - basics.py - tta_standard - TTA Epoch1: [171/473]	Time 1.836 (1.896)	Loss reg 4.8010 (6.0081)	Loss consis 0.0104 (0.6462)	Prec@1 0.000 (5.015)	Prec@5 62.500 (32.340)
2025-05-27 20:49:57,766 - 10 - basics.py - tta_standard - TTA Epoch1: [172/473]	Time 1.837 (1.896)	Loss reg 4.7759 (6.0009)	Loss consis 0.1474 (0.6433)	Prec@1 0.000 (4.986)	Prec@5 25.000 (32.298)
2025-05-27 20:49:59,605 - 10 - basics.py - tta_standard - TTA Epoch1: [173/473]	Time 1.839 (1.895)	Loss reg 4.7709 (5.9939)	Loss consis 0.1646 (0.6405)	Prec@1 0.000 (4.957)	Prec@5 37.500 (32.328)
2025-05-27 20:50:01,439 - 10 - basics.py - tta_standard - TTA Epoch1: [174/473]	Time 1.834 (1.895)	Loss reg 4.7620 (5.9868)	Loss consis 0.9337 (0.6422)	Prec@1 0.000 (4.929)	Prec@5 50.000 (32.429)
2025-05-27 20:50:03,271 - 10 - basics.py - tta_standard - TTA Epoch1: [175/473]	Time 1.833 (1.895)	Loss reg 4.7575 (5.9798)	Loss consis 0.4968 (0.6414)	Prec@1 0.000 (4.901)	Prec@5 37.500 (32.457)
2025-05-27 20:50:05,109 - 10 - basics.py - tta_standard - TTA Epoch1: [176/473]	Time 1.837 (1.894)	Loss reg 4.7300 (5.9728)	Loss consis 0.9936 (0.6434)	Prec@1 12.500 (4.944)	Prec@5 50.000 (32.556)
2025-05-27 20:50:06,946 - 10 - basics.py - tta_standard - TTA Epoch1: [177/473]	Time 1.837 (1.894)	Loss reg 4.7186 (5.9657)	Loss consis 0.8520 (0.6445)	Prec@1 0.000 (4.916)	Prec@5 50.000 (32.654)
2025-05-27 20:50:08,785 - 10 - basics.py - tta_standard - TTA Epoch1: [178/473]	Time 1.840 (1.894)	Loss reg 4.7218 (5.9588)	Loss consis 0.0658 (0.6413)	Prec@1 12.500 (4.958)	Prec@5 62.500 (32.821)
2025-05-27 20:50:10,621 - 10 - basics.py - tta_standard - TTA Epoch1: [179/473]	Time 1.836 (1.893)	Loss reg 4.7208 (5.9519)	Loss consis 0.0074 (0.6378)	Prec@1 0.000 (4.931)	Prec@5 0.000 (32.639)
2025-05-27 20:50:12,460 - 10 - basics.py - tta_standard - TTA Epoch1: [180/473]	Time 1.839 (1.893)	Loss reg 4.7213 (5.9451)	Loss consis 0.1708 (0.6352)	Prec@1 0.000 (4.903)	Prec@5 25.000 (32.597)
2025-05-27 20:50:14,294 - 10 - basics.py - tta_standard - TTA Epoch1: [181/473]	Time 1.834 (1.893)	Loss reg 4.7276 (5.9384)	Loss consis 0.0422 (0.6319)	Prec@1 0.000 (4.876)	Prec@5 25.000 (32.555)
2025-05-27 20:50:16,130 - 10 - basics.py - tta_standard - TTA Epoch1: [182/473]	Time 1.836 (1.892)	Loss reg 4.7321 (5.9318)	Loss consis 0.0416 (0.6287)	Prec@1 0.000 (4.850)	Prec@5 75.000 (32.787)
2025-05-27 20:50:17,965 - 10 - basics.py - tta_standard - TTA Epoch1: [183/473]	Time 1.835 (1.892)	Loss reg 4.7307 (5.9253)	Loss consis 0.7744 (0.6295)	Prec@1 0.000 (4.823)	Prec@5 37.500 (32.812)
2025-05-27 20:50:19,801 - 10 - basics.py - tta_standard - TTA Epoch1: [184/473]	Time 1.836 (1.892)	Loss reg 4.7032 (5.9187)	Loss consis 0.0813 (0.6265)	Prec@1 12.500 (4.865)	Prec@5 50.000 (32.905)
2025-05-27 20:50:21,637 - 10 - basics.py - tta_standard - TTA Epoch1: [185/473]	Time 1.836 (1.892)	Loss reg 4.7237 (5.9123)	Loss consis 0.0057 (0.6232)	Prec@1 0.000 (4.839)	Prec@5 25.000 (32.863)
2025-05-27 20:50:23,472 - 10 - basics.py - tta_standard - TTA Epoch1: [186/473]	Time 1.836 (1.891)	Loss reg 4.7166 (5.9059)	Loss consis 0.0115 (0.6199)	Prec@1 0.000 (4.813)	Prec@5 25.000 (32.821)
2025-05-27 20:50:25,310 - 10 - basics.py - tta_standard - TTA Epoch1: [187/473]	Time 1.837 (1.891)	Loss reg 4.6961 (5.8994)	Loss consis 0.5985 (0.6198)	Prec@1 12.500 (4.854)	Prec@5 50.000 (32.912)
2025-05-27 20:50:27,146 - 10 - basics.py - tta_standard - TTA Epoch1: [188/473]	Time 1.837 (1.891)	Loss reg 4.6930 (5.8931)	Loss consis 0.0489 (0.6168)	Prec@1 0.000 (4.828)	Prec@5 37.500 (32.937)
2025-05-27 20:50:28,983 - 10 - basics.py - tta_standard - TTA Epoch1: [189/473]	Time 1.836 (1.890)	Loss reg 4.6973 (5.8868)	Loss consis 0.0733 (0.6139)	Prec@1 0.000 (4.803)	Prec@5 12.500 (32.829)
2025-05-27 20:50:30,821 - 10 - basics.py - tta_standard - TTA Epoch1: [190/473]	Time 1.839 (1.890)	Loss reg 4.6630 (5.8804)	Loss consis 0.0702 (0.6111)	Prec@1 12.500 (4.843)	Prec@5 25.000 (32.788)
2025-05-27 20:50:32,659 - 10 - basics.py - tta_standard - TTA Epoch1: [191/473]	Time 1.837 (1.890)	Loss reg 4.6743 (5.8741)	Loss consis 0.0052 (0.6079)	Prec@1 0.000 (4.818)	Prec@5 12.500 (32.682)
2025-05-27 20:50:34,495 - 10 - basics.py - tta_standard - TTA Epoch1: [192/473]	Time 1.837 (1.890)	Loss reg 4.6539 (5.8677)	Loss consis 0.1702 (0.6057)	Prec@1 0.000 (4.793)	Prec@5 75.000 (32.902)
2025-05-27 20:50:36,331 - 10 - basics.py - tta_standard - TTA Epoch1: [193/473]	Time 1.835 (1.889)	Loss reg 4.6574 (5.8615)	Loss consis 0.0918 (0.6030)	Prec@1 0.000 (4.768)	Prec@5 0.000 (32.732)
2025-05-27 20:50:38,166 - 10 - basics.py - tta_standard - TTA Epoch1: [194/473]	Time 1.835 (1.889)	Loss reg 4.6677 (5.8554)	Loss consis 0.2228 (0.6011)	Prec@1 12.500 (4.808)	Prec@5 25.000 (32.692)
2025-05-27 20:50:40,006 - 10 - basics.py - tta_standard - TTA Epoch1: [195/473]	Time 1.840 (1.889)	Loss reg 4.6681 (5.8493)	Loss consis 0.2652 (0.5994)	Prec@1 0.000 (4.783)	Prec@5 25.000 (32.653)
2025-05-27 20:50:41,846 - 10 - basics.py - tta_standard - TTA Epoch1: [196/473]	Time 1.840 (1.888)	Loss reg 4.6652 (5.8433)	Loss consis 0.0803 (0.5967)	Prec@1 0.000 (4.759)	Prec@5 25.000 (32.614)
2025-05-27 20:50:43,687 - 10 - basics.py - tta_standard - TTA Epoch1: [197/473]	Time 1.840 (1.888)	Loss reg 4.6809 (5.8374)	Loss consis 0.0227 (0.5938)	Prec@1 0.000 (4.735)	Prec@5 12.500 (32.513)
2025-05-27 20:50:45,525 - 10 - basics.py - tta_standard - TTA Epoch1: [198/473]	Time 1.838 (1.888)	Loss reg 4.6349 (5.8314)	Loss consis 0.1235 (0.5915)	Prec@1 0.000 (4.711)	Prec@5 62.500 (32.663)
2025-05-27 20:50:47,363 - 10 - basics.py - tta_standard - TTA Epoch1: [199/473]	Time 1.838 (1.888)	Loss reg 4.6278 (5.8254)	Loss consis 1.1485 (0.5942)	Prec@1 0.000 (4.688)	Prec@5 25.000 (32.625)
2025-05-27 20:50:49,203 - 10 - basics.py - tta_standard - TTA Epoch1: [200/473]	Time 1.841 (1.888)	Loss reg 4.6191 (5.8194)	Loss consis 0.6541 (0.5945)	Prec@1 12.500 (4.726)	Prec@5 37.500 (32.649)
2025-05-27 20:50:51,041 - 10 - basics.py - tta_standard - TTA Epoch1: [201/473]	Time 1.838 (1.887)	Loss reg 4.6039 (5.8134)	Loss consis 0.2749 (0.5930)	Prec@1 0.000 (4.703)	Prec@5 50.000 (32.735)
2025-05-27 20:50:52,881 - 10 - basics.py - tta_standard - TTA Epoch1: [202/473]	Time 1.840 (1.887)	Loss reg 4.6330 (5.8076)	Loss consis 0.0119 (0.5901)	Prec@1 12.500 (4.741)	Prec@5 25.000 (32.697)
2025-05-27 20:50:54,715 - 10 - basics.py - tta_standard - TTA Epoch1: [203/473]	Time 1.834 (1.887)	Loss reg 4.6699 (5.8020)	Loss consis 0.0010 (0.5872)	Prec@1 0.000 (4.718)	Prec@5 12.500 (32.598)
2025-05-27 20:50:56,554 - 10 - basics.py - tta_standard - TTA Epoch1: [204/473]	Time 1.839 (1.887)	Loss reg 4.6434 (5.7963)	Loss consis 0.6288 (0.5874)	Prec@1 0.000 (4.695)	Prec@5 25.000 (32.561)
2025-05-27 20:50:58,392 - 10 - basics.py - tta_standard - TTA Epoch1: [205/473]	Time 1.838 (1.886)	Loss reg 4.6204 (5.7906)	Loss consis 0.6333 (0.5876)	Prec@1 0.000 (4.672)	Prec@5 25.000 (32.524)
2025-05-27 20:51:00,230 - 10 - basics.py - tta_standard - TTA Epoch1: [206/473]	Time 1.838 (1.886)	Loss reg 4.6512 (5.7851)	Loss consis 0.0278 (0.5849)	Prec@1 0.000 (4.650)	Prec@5 50.000 (32.609)
2025-05-27 20:51:02,069 - 10 - basics.py - tta_standard - TTA Epoch1: [207/473]	Time 1.839 (1.886)	Loss reg 4.6595 (5.7797)	Loss consis 0.0673 (0.5824)	Prec@1 0.000 (4.627)	Prec@5 37.500 (32.632)
2025-05-27 20:51:03,909 - 10 - basics.py - tta_standard - TTA Epoch1: [208/473]	Time 1.840 (1.886)	Loss reg 4.6377 (5.7742)	Loss consis 0.0057 (0.5797)	Prec@1 0.000 (4.605)	Prec@5 50.000 (32.715)
2025-05-27 20:51:05,749 - 10 - basics.py - tta_standard - TTA Epoch1: [209/473]	Time 1.840 (1.885)	Loss reg 4.6249 (5.7688)	Loss consis 0.0203 (0.5770)	Prec@1 0.000 (4.583)	Prec@5 25.000 (32.679)
2025-05-27 20:51:07,586 - 10 - basics.py - tta_standard - TTA Epoch1: [210/473]	Time 1.837 (1.885)	Loss reg 4.6115 (5.7633)	Loss consis 0.1654 (0.5751)	Prec@1 0.000 (4.562)	Prec@5 12.500 (32.583)
2025-05-27 20:51:09,423 - 10 - basics.py - tta_standard - TTA Epoch1: [211/473]	Time 1.838 (1.885)	Loss reg 4.6005 (5.7578)	Loss consis 0.0484 (0.5726)	Prec@1 0.000 (4.540)	Prec@5 50.000 (32.665)
2025-05-27 20:51:11,260 - 10 - basics.py - tta_standard - TTA Epoch1: [212/473]	Time 1.836 (1.885)	Loss reg 4.6030 (5.7524)	Loss consis 0.0901 (0.5703)	Prec@1 0.000 (4.519)	Prec@5 0.000 (32.512)
2025-05-27 20:51:13,095 - 10 - basics.py - tta_standard - TTA Epoch1: [213/473]	Time 1.835 (1.884)	Loss reg 4.5714 (5.7469)	Loss consis 0.3732 (0.5694)	Prec@1 0.000 (4.498)	Prec@5 50.000 (32.593)
2025-05-27 20:51:14,930 - 10 - basics.py - tta_standard - TTA Epoch1: [214/473]	Time 1.835 (1.884)	Loss reg 4.5448 (5.7413)	Loss consis 0.6675 (0.5699)	Prec@1 25.000 (4.593)	Prec@5 62.500 (32.733)
2025-05-27 20:51:16,769 - 10 - basics.py - tta_standard - TTA Epoch1: [215/473]	Time 1.840 (1.884)	Loss reg 4.5313 (5.7357)	Loss consis 0.6180 (0.5701)	Prec@1 12.500 (4.630)	Prec@5 12.500 (32.639)
2025-05-27 20:51:18,609 - 10 - basics.py - tta_standard - TTA Epoch1: [216/473]	Time 1.839 (1.884)	Loss reg 4.5436 (5.7302)	Loss consis 0.0127 (0.5675)	Prec@1 0.000 (4.608)	Prec@5 25.000 (32.604)
2025-05-27 20:51:20,449 - 10 - basics.py - tta_standard - TTA Epoch1: [217/473]	Time 1.840 (1.884)	Loss reg 4.4861 (5.7245)	Loss consis 1.9268 (0.5737)	Prec@1 12.500 (4.644)	Prec@5 62.500 (32.741)
2025-05-27 20:51:22,294 - 10 - basics.py - tta_standard - TTA Epoch1: [218/473]	Time 1.846 (1.883)	Loss reg 4.5054 (5.7189)	Loss consis 0.0658 (0.5714)	Prec@1 0.000 (4.623)	Prec@5 12.500 (32.648)
2025-05-27 20:51:24,132 - 10 - basics.py - tta_standard - TTA Epoch1: [219/473]	Time 1.838 (1.883)	Loss reg 4.4892 (5.7133)	Loss consis 0.0291 (0.5690)	Prec@1 0.000 (4.602)	Prec@5 12.500 (32.557)
2025-05-27 20:51:25,966 - 10 - basics.py - tta_standard - TTA Epoch1: [220/473]	Time 1.834 (1.883)	Loss reg 4.4911 (5.7078)	Loss consis 0.0472 (0.5666)	Prec@1 0.000 (4.581)	Prec@5 62.500 (32.692)
2025-05-27 20:51:27,804 - 10 - basics.py - tta_standard - TTA Epoch1: [221/473]	Time 1.838 (1.883)	Loss reg 4.4944 (5.7023)	Loss consis 0.8629 (0.5679)	Prec@1 0.000 (4.561)	Prec@5 25.000 (32.658)
2025-05-27 20:51:29,644 - 10 - basics.py - tta_standard - TTA Epoch1: [222/473]	Time 1.840 (1.883)	Loss reg 4.4829 (5.6968)	Loss consis 0.3416 (0.5669)	Prec@1 0.000 (4.540)	Prec@5 37.500 (32.679)
2025-05-27 20:51:31,481 - 10 - basics.py - tta_standard - TTA Epoch1: [223/473]	Time 1.838 (1.882)	Loss reg 4.4684 (5.6914)	Loss consis 0.7890 (0.5679)	Prec@1 0.000 (4.520)	Prec@5 62.500 (32.812)
2025-05-27 20:51:33,318 - 10 - basics.py - tta_standard - TTA Epoch1: [224/473]	Time 1.837 (1.882)	Loss reg 4.4403 (5.6858)	Loss consis 0.3049 (0.5667)	Prec@1 0.000 (4.500)	Prec@5 50.000 (32.889)
2025-05-27 20:51:35,155 - 10 - basics.py - tta_standard - TTA Epoch1: [225/473]	Time 1.836 (1.882)	Loss reg 4.4252 (5.6802)	Loss consis 0.4621 (0.5663)	Prec@1 0.000 (4.480)	Prec@5 62.500 (33.020)
2025-05-27 20:51:36,997 - 10 - basics.py - tta_standard - TTA Epoch1: [226/473]	Time 1.842 (1.882)	Loss reg 4.4269 (5.6747)	Loss consis 0.0679 (0.5641)	Prec@1 0.000 (4.460)	Prec@5 25.000 (32.985)
2025-05-27 20:51:38,836 - 10 - basics.py - tta_standard - TTA Epoch1: [227/473]	Time 1.839 (1.882)	Loss reg 4.4235 (5.6692)	Loss consis 1.0309 (0.5661)	Prec@1 0.000 (4.441)	Prec@5 37.500 (33.004)
2025-05-27 20:51:40,674 - 10 - basics.py - tta_standard - TTA Epoch1: [228/473]	Time 1.838 (1.881)	Loss reg 4.4401 (5.6638)	Loss consis 0.0888 (0.5640)	Prec@1 0.000 (4.421)	Prec@5 25.000 (32.969)
2025-05-27 20:51:42,513 - 10 - basics.py - tta_standard - TTA Epoch1: [229/473]	Time 1.839 (1.881)	Loss reg 4.4159 (5.6584)	Loss consis 0.1832 (0.5624)	Prec@1 25.000 (4.511)	Prec@5 75.000 (33.152)
2025-05-27 20:51:44,349 - 10 - basics.py - tta_standard - TTA Epoch1: [230/473]	Time 1.836 (1.881)	Loss reg 4.4046 (5.6530)	Loss consis 0.5394 (0.5623)	Prec@1 0.000 (4.491)	Prec@5 25.000 (33.117)
2025-05-27 20:51:46,188 - 10 - basics.py - tta_standard - TTA Epoch1: [231/473]	Time 1.838 (1.881)	Loss reg 4.4109 (5.6476)	Loss consis 0.1831 (0.5607)	Prec@1 0.000 (4.472)	Prec@5 37.500 (33.136)
2025-05-27 20:51:48,025 - 10 - basics.py - tta_standard - TTA Epoch1: [232/473]	Time 1.838 (1.881)	Loss reg 4.4237 (5.6424)	Loss consis 0.0391 (0.5584)	Prec@1 0.000 (4.453)	Prec@5 25.000 (33.101)
2025-05-27 20:51:49,859 - 10 - basics.py - tta_standard - TTA Epoch1: [233/473]	Time 1.834 (1.881)	Loss reg 4.3806 (5.6370)	Loss consis 0.4058 (0.5578)	Prec@1 0.000 (4.434)	Prec@5 25.000 (33.066)
2025-05-27 20:51:51,695 - 10 - basics.py - tta_standard - TTA Epoch1: [234/473]	Time 1.836 (1.880)	Loss reg 4.3257 (5.6314)	Loss consis 0.3107 (0.5567)	Prec@1 0.000 (4.415)	Prec@5 50.000 (33.138)
2025-05-27 20:51:53,534 - 10 - basics.py - tta_standard - TTA Epoch1: [235/473]	Time 1.839 (1.880)	Loss reg 4.3307 (5.6259)	Loss consis 0.1161 (0.5548)	Prec@1 0.000 (4.396)	Prec@5 25.000 (33.104)
2025-05-27 20:51:55,374 - 10 - basics.py - tta_standard - TTA Epoch1: [236/473]	Time 1.840 (1.880)	Loss reg 4.3315 (5.6204)	Loss consis 0.0086 (0.5525)	Prec@1 0.000 (4.378)	Prec@5 37.500 (33.122)
2025-05-27 20:51:57,210 - 10 - basics.py - tta_standard - TTA Epoch1: [237/473]	Time 1.836 (1.880)	Loss reg 4.3053 (5.6149)	Loss consis 0.7297 (0.5533)	Prec@1 12.500 (4.412)	Prec@5 37.500 (33.141)
2025-05-27 20:51:59,046 - 10 - basics.py - tta_standard - TTA Epoch1: [238/473]	Time 1.836 (1.880)	Loss reg 4.3198 (5.6095)	Loss consis 0.0312 (0.5511)	Prec@1 0.000 (4.393)	Prec@5 50.000 (33.211)
2025-05-27 20:52:00,882 - 10 - basics.py - tta_standard - TTA Epoch1: [239/473]	Time 1.836 (1.879)	Loss reg 4.3053 (5.6041)	Loss consis 0.1896 (0.5496)	Prec@1 12.500 (4.427)	Prec@5 50.000 (33.281)
2025-05-27 20:52:02,721 - 10 - basics.py - tta_standard - TTA Epoch1: [240/473]	Time 1.839 (1.879)	Loss reg 4.3156 (5.5987)	Loss consis 0.3559 (0.5488)	Prec@1 0.000 (4.409)	Prec@5 50.000 (33.351)
2025-05-27 20:52:04,558 - 10 - basics.py - tta_standard - TTA Epoch1: [241/473]	Time 1.837 (1.879)	Loss reg 4.3595 (5.5936)	Loss consis 0.1105 (0.5470)	Prec@1 0.000 (4.390)	Prec@5 37.500 (33.368)
2025-05-27 20:52:06,395 - 10 - basics.py - tta_standard - TTA Epoch1: [242/473]	Time 1.837 (1.879)	Loss reg 4.3550 (5.5885)	Loss consis 0.0093 (0.5448)	Prec@1 0.000 (4.372)	Prec@5 37.500 (33.385)
2025-05-27 20:52:08,235 - 10 - basics.py - tta_standard - TTA Epoch1: [243/473]	Time 1.840 (1.879)	Loss reg 4.3745 (5.5835)	Loss consis 0.0026 (0.5425)	Prec@1 0.000 (4.355)	Prec@5 25.000 (33.350)
2025-05-27 20:52:10,071 - 10 - basics.py - tta_standard - TTA Epoch1: [244/473]	Time 1.836 (1.879)	Loss reg 4.3940 (5.5787)	Loss consis 0.0209 (0.5404)	Prec@1 0.000 (4.337)	Prec@5 37.500 (33.367)
2025-05-27 20:52:11,910 - 10 - basics.py - tta_standard - TTA Epoch1: [245/473]	Time 1.838 (1.878)	Loss reg 4.3976 (5.5739)	Loss consis 0.0100 (0.5383)	Prec@1 0.000 (4.319)	Prec@5 62.500 (33.486)
2025-05-27 20:52:13,746 - 10 - basics.py - tta_standard - TTA Epoch1: [246/473]	Time 1.836 (1.878)	Loss reg 4.3484 (5.5689)	Loss consis 0.5768 (0.5384)	Prec@1 0.000 (4.302)	Prec@5 12.500 (33.401)
2025-05-27 20:52:15,580 - 10 - basics.py - tta_standard - TTA Epoch1: [247/473]	Time 1.835 (1.878)	Loss reg 4.3468 (5.5640)	Loss consis 0.0157 (0.5363)	Prec@1 12.500 (4.335)	Prec@5 50.000 (33.468)
2025-05-27 20:52:17,415 - 10 - basics.py - tta_standard - TTA Epoch1: [248/473]	Time 1.835 (1.878)	Loss reg 4.3246 (5.5590)	Loss consis 0.0432 (0.5343)	Prec@1 0.000 (4.317)	Prec@5 37.500 (33.484)
2025-05-27 20:52:19,250 - 10 - basics.py - tta_standard - TTA Epoch1: [249/473]	Time 1.835 (1.878)	Loss reg 4.3445 (5.5541)	Loss consis 0.0171 (0.5323)	Prec@1 0.000 (4.300)	Prec@5 37.500 (33.500)
2025-05-27 20:52:21,087 - 10 - basics.py - tta_standard - TTA Epoch1: [250/473]	Time 1.837 (1.878)	Loss reg 4.3341 (5.5493)	Loss consis 0.3702 (0.5316)	Prec@1 12.500 (4.333)	Prec@5 50.000 (33.566)
2025-05-27 20:52:22,923 - 10 - basics.py - tta_standard - TTA Epoch1: [251/473]	Time 1.836 (1.877)	Loss reg 4.3489 (5.5445)	Loss consis 0.0394 (0.5297)	Prec@1 0.000 (4.315)	Prec@5 50.000 (33.631)
2025-05-27 20:52:24,758 - 10 - basics.py - tta_standard - TTA Epoch1: [252/473]	Time 1.835 (1.877)	Loss reg 4.3857 (5.5399)	Loss consis 0.1274 (0.5281)	Prec@1 0.000 (4.298)	Prec@5 37.500 (33.646)
2025-05-27 20:52:26,594 - 10 - basics.py - tta_standard - TTA Epoch1: [253/473]	Time 1.836 (1.877)	Loss reg 4.3968 (5.5354)	Loss consis 0.0069 (0.5260)	Prec@1 0.000 (4.281)	Prec@5 12.500 (33.563)
2025-05-27 20:52:28,427 - 10 - basics.py - tta_standard - TTA Epoch1: [254/473]	Time 1.833 (1.877)	Loss reg 4.3819 (5.5309)	Loss consis 0.0765 (0.5243)	Prec@1 12.500 (4.314)	Prec@5 37.500 (33.578)
2025-05-27 20:52:30,264 - 10 - basics.py - tta_standard - TTA Epoch1: [255/473]	Time 1.837 (1.877)	Loss reg 4.3736 (5.5264)	Loss consis 0.0054 (0.5222)	Prec@1 0.000 (4.297)	Prec@5 25.000 (33.545)
2025-05-27 20:52:32,101 - 10 - basics.py - tta_standard - TTA Epoch1: [256/473]	Time 1.837 (1.877)	Loss reg 4.3965 (5.5220)	Loss consis 0.0043 (0.5202)	Prec@1 0.000 (4.280)	Prec@5 12.500 (33.463)
2025-05-27 20:52:33,935 - 10 - basics.py - tta_standard - TTA Epoch1: [257/473]	Time 1.834 (1.876)	Loss reg 4.4073 (5.5177)	Loss consis 0.0071 (0.5182)	Prec@1 0.000 (4.264)	Prec@5 37.500 (33.479)
2025-05-27 20:52:35,773 - 10 - basics.py - tta_standard - TTA Epoch1: [258/473]	Time 1.838 (1.876)	Loss reg 4.4107 (5.5134)	Loss consis 0.0221 (0.5163)	Prec@1 0.000 (4.247)	Prec@5 25.000 (33.446)
2025-05-27 20:52:37,612 - 10 - basics.py - tta_standard - TTA Epoch1: [259/473]	Time 1.838 (1.876)	Loss reg 4.4192 (5.5092)	Loss consis 0.0198 (0.5144)	Prec@1 0.000 (4.231)	Prec@5 25.000 (33.413)
2025-05-27 20:52:39,450 - 10 - basics.py - tta_standard - TTA Epoch1: [260/473]	Time 1.838 (1.876)	Loss reg 4.3869 (5.5049)	Loss consis 0.1276 (0.5129)	Prec@1 0.000 (4.215)	Prec@5 62.500 (33.525)
2025-05-27 20:52:41,285 - 10 - basics.py - tta_standard - TTA Epoch1: [261/473]	Time 1.835 (1.876)	Loss reg 4.4026 (5.5007)	Loss consis 0.0154 (0.5110)	Prec@1 0.000 (4.198)	Prec@5 12.500 (33.445)
2025-05-27 20:52:43,125 - 10 - basics.py - tta_standard - TTA Epoch1: [262/473]	Time 1.840 (1.876)	Loss reg 4.3534 (5.4963)	Loss consis 0.1631 (0.5097)	Prec@1 0.000 (4.183)	Prec@5 50.000 (33.508)
2025-05-27 20:52:44,959 - 10 - basics.py - tta_standard - TTA Epoch1: [263/473]	Time 1.834 (1.876)	Loss reg 4.3355 (5.4919)	Loss consis 0.2244 (0.5086)	Prec@1 0.000 (4.167)	Prec@5 62.500 (33.617)
2025-05-27 20:52:46,793 - 10 - basics.py - tta_standard - TTA Epoch1: [264/473]	Time 1.834 (1.875)	Loss reg 4.3305 (5.4875)	Loss consis 0.8588 (0.5099)	Prec@1 0.000 (4.151)	Prec@5 50.000 (33.679)
2025-05-27 20:52:48,635 - 10 - basics.py - tta_standard - TTA Epoch1: [265/473]	Time 1.842 (1.875)	Loss reg 4.3289 (5.4832)	Loss consis 0.0231 (0.5081)	Prec@1 0.000 (4.135)	Prec@5 37.500 (33.694)
2025-05-27 20:52:50,469 - 10 - basics.py - tta_standard - TTA Epoch1: [266/473]	Time 1.834 (1.875)	Loss reg 4.3279 (5.4789)	Loss consis 0.8799 (0.5095)	Prec@1 12.500 (4.167)	Prec@5 75.000 (33.848)
2025-05-27 20:52:52,304 - 10 - basics.py - tta_standard - TTA Epoch1: [267/473]	Time 1.835 (1.875)	Loss reg 4.3309 (5.4746)	Loss consis 0.2264 (0.5084)	Prec@1 0.000 (4.151)	Prec@5 50.000 (33.909)
2025-05-27 20:52:54,140 - 10 - basics.py - tta_standard - TTA Epoch1: [268/473]	Time 1.836 (1.875)	Loss reg 4.3485 (5.4704)	Loss consis 0.8106 (0.5096)	Prec@1 12.500 (4.182)	Prec@5 25.000 (33.875)
2025-05-27 20:52:55,977 - 10 - basics.py - tta_standard - TTA Epoch1: [269/473]	Time 1.836 (1.875)	Loss reg 4.3456 (5.4662)	Loss consis 0.0512 (0.5079)	Prec@1 0.000 (4.167)	Prec@5 0.000 (33.750)
2025-05-27 20:52:57,817 - 10 - basics.py - tta_standard - TTA Epoch1: [270/473]	Time 1.840 (1.875)	Loss reg 4.3129 (5.4620)	Loss consis 0.0515 (0.5062)	Prec@1 0.000 (4.151)	Prec@5 62.500 (33.856)
2025-05-27 20:52:59,663 - 10 - basics.py - tta_standard - TTA Epoch1: [271/473]	Time 1.846 (1.874)	Loss reg 4.2808 (5.4576)	Loss consis 0.3370 (0.5056)	Prec@1 0.000 (4.136)	Prec@5 50.000 (33.915)
2025-05-27 20:53:01,502 - 10 - basics.py - tta_standard - TTA Epoch1: [272/473]	Time 1.839 (1.874)	Loss reg 4.2793 (5.4533)	Loss consis 0.1580 (0.5043)	Prec@1 0.000 (4.121)	Prec@5 37.500 (33.929)
2025-05-27 20:53:03,338 - 10 - basics.py - tta_standard - TTA Epoch1: [273/473]	Time 1.836 (1.874)	Loss reg 4.3004 (5.4491)	Loss consis 0.0567 (0.5027)	Prec@1 0.000 (4.106)	Prec@5 37.500 (33.942)
2025-05-27 20:53:05,174 - 10 - basics.py - tta_standard - TTA Epoch1: [274/473]	Time 1.837 (1.874)	Loss reg 4.3006 (5.4449)	Loss consis 0.6384 (0.5032)	Prec@1 0.000 (4.091)	Prec@5 50.000 (34.000)
2025-05-27 20:53:07,010 - 10 - basics.py - tta_standard - TTA Epoch1: [275/473]	Time 1.836 (1.874)	Loss reg 4.3114 (5.4408)	Loss consis 0.8180 (0.5043)	Prec@1 0.000 (4.076)	Prec@5 37.500 (34.013)
2025-05-27 20:53:08,845 - 10 - basics.py - tta_standard - TTA Epoch1: [276/473]	Time 1.834 (1.874)	Loss reg 4.2828 (5.4366)	Loss consis 0.5419 (0.5044)	Prec@1 0.000 (4.061)	Prec@5 25.000 (33.980)
2025-05-27 20:53:10,680 - 10 - basics.py - tta_standard - TTA Epoch1: [277/473]	Time 1.835 (1.874)	Loss reg 4.2811 (5.4325)	Loss consis 0.2651 (0.5036)	Prec@1 0.000 (4.047)	Prec@5 37.500 (33.993)
2025-05-27 20:53:12,519 - 10 - basics.py - tta_standard - TTA Epoch1: [278/473]	Time 1.839 (1.873)	Loss reg 4.2969 (5.4284)	Loss consis 0.1421 (0.5023)	Prec@1 0.000 (4.032)	Prec@5 37.500 (34.005)
2025-05-27 20:53:14,356 - 10 - basics.py - tta_standard - TTA Epoch1: [279/473]	Time 1.837 (1.873)	Loss reg 4.2931 (5.4244)	Loss consis 0.0269 (0.5006)	Prec@1 0.000 (4.018)	Prec@5 0.000 (33.884)
2025-05-27 20:53:16,194 - 10 - basics.py - tta_standard - TTA Epoch1: [280/473]	Time 1.838 (1.873)	Loss reg 4.3250 (5.4204)	Loss consis 0.0039 (0.4988)	Prec@1 12.500 (4.048)	Prec@5 25.000 (33.852)
2025-05-27 20:53:18,031 - 10 - basics.py - tta_standard - TTA Epoch1: [281/473]	Time 1.837 (1.873)	Loss reg 4.4037 (5.4168)	Loss consis 0.0007 (0.4970)	Prec@1 0.000 (4.034)	Prec@5 50.000 (33.910)
2025-05-27 20:53:19,865 - 10 - basics.py - tta_standard - TTA Epoch1: [282/473]	Time 1.834 (1.873)	Loss reg 4.3588 (5.4131)	Loss consis 0.2390 (0.4961)	Prec@1 0.000 (4.019)	Prec@5 12.500 (33.834)
2025-05-27 20:53:21,700 - 10 - basics.py - tta_standard - TTA Epoch1: [283/473]	Time 1.835 (1.873)	Loss reg 4.3778 (5.4095)	Loss consis 0.0061 (0.4944)	Prec@1 0.000 (4.005)	Prec@5 62.500 (33.935)
2025-05-27 20:53:23,540 - 10 - basics.py - tta_standard - TTA Epoch1: [284/473]	Time 1.840 (1.873)	Loss reg 4.3770 (5.4058)	Loss consis 0.0101 (0.4927)	Prec@1 0.000 (3.991)	Prec@5 37.500 (33.947)
2025-05-27 20:53:25,377 - 10 - basics.py - tta_standard - TTA Epoch1: [285/473]	Time 1.838 (1.873)	Loss reg 4.3920 (5.4023)	Loss consis 0.1625 (0.4915)	Prec@1 0.000 (3.977)	Prec@5 37.500 (33.960)
2025-05-27 20:53:27,214 - 10 - basics.py - tta_standard - TTA Epoch1: [286/473]	Time 1.836 (1.872)	Loss reg 4.4064 (5.3988)	Loss consis 0.0356 (0.4900)	Prec@1 0.000 (3.963)	Prec@5 62.500 (34.059)
2025-05-27 20:53:29,050 - 10 - basics.py - tta_standard - TTA Epoch1: [287/473]	Time 1.837 (1.872)	Loss reg 4.4153 (5.3954)	Loss consis 0.0394 (0.4884)	Prec@1 0.000 (3.950)	Prec@5 25.000 (34.028)
2025-05-27 20:53:30,892 - 10 - basics.py - tta_standard - TTA Epoch1: [288/473]	Time 1.842 (1.872)	Loss reg 4.4343 (5.3921)	Loss consis 0.0018 (0.4867)	Prec@1 0.000 (3.936)	Prec@5 37.500 (34.040)
2025-05-27 20:53:32,727 - 10 - basics.py - tta_standard - TTA Epoch1: [289/473]	Time 1.835 (1.872)	Loss reg 4.3773 (5.3886)	Loss consis 0.9352 (0.4883)	Prec@1 0.000 (3.922)	Prec@5 37.500 (34.052)
